{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                         1\n",
      "title      What is the right approach to write the spin c...\n",
      "content    <p>Imagine programming a 3 wheel soccer robot....\n",
      "tags                                          soccer control\n",
      "Name: 0, dtype: object\n",
      "id                                                         2\n",
      "title      How can I modify a low cost hobby servo to run...\n",
      "content    <p>I've got some hobby servos (<a href=\"http:/...\n",
      "tags                                         control rcservo\n",
      "Name: 1, dtype: object\n",
      "id                                                         3\n",
      "title      What useful gaits exist for a six legged robot...\n",
      "content    <p><a href=\"http://www.oricomtech.com/projects...\n",
      "tags                                               gait walk\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "robotics = pd.read_csv(\"data/robotics.csv\")\n",
    "cooking = pd.read_csv(\"data/cooking.csv\")\n",
    "biology = pd.read_csv(\"data/biology.csv\")\n",
    "crypto = pd.read_csv(\"data/crypto.csv\")\n",
    "travel = pd.read_csv(\"data/travel.csv\")\n",
    "diy = pd.read_csv(\"data/diy.csv\")             \n",
    "test = pd.read_csv(\"data/test.csv\") \n",
    "\n",
    "df_hash = {\n",
    "    \"cooking\": cooking,\n",
    "    \"crypto\": crypto,\n",
    "    \"robotics\": robotics,\n",
    "    \"biology\": biology,\n",
    "    \"travel\": travel,\n",
    "    \"diy\":diy,\n",
    "    \"test\": test\n",
    "    \n",
    "}\n",
    "\n",
    "print(df_hash[\"robotics\"].iloc[0])\n",
    "print df_hash[\"robotics\"].iloc[1]\n",
    "print(df_hash[\"robotics\"].iloc[2])\n",
    "# print df_hash[\"biology\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'title' 'content' 'tags']\n",
      "   id                                              title  \\\n",
      "0   1  What is spin as it relates to subatomic partic...   \n",
      "1   2  What is your simplest explanation of the strin...   \n",
      "2   3   Lie theory, Representations and particle physics   \n",
      "3   7                 Will Determinism be ever possible?   \n",
      "4   9                               Hamilton's Principle   \n",
      "\n",
      "                                             content  \n",
      "0  <p>I often hear about subatomic particles havi...  \n",
      "1  <p>How would you explain string theory to non ...  \n",
      "2  <p>This is a question that has been posted at ...  \n",
      "3  <p>What are the main problems that we need to ...  \n",
      "4  <p>Hamilton's principle states that a dynamic ...  \n"
     ]
    }
   ],
   "source": [
    "print df_hash['robotics'].columns.values\n",
    "print df_hash['test'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology: 13196\n",
      "cooking: 15404\n",
      "travel: 19279\n",
      "robotics: 2771\n",
      "crypto: 10432\n",
      "diy: 25918\n",
      "test: 81926\n"
     ]
    }
   ],
   "source": [
    " for topic, df in df_hash.iteritems():\n",
    "    print topic + \": \" +  str(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "# In Python, searching a set is much faster than searching a list, so convert the stop words to a set\n",
    "stops = set(stopwords.words(\"english\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/word2vec-nlp-tutorial#part-1-for-beginners-bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def separate_tags(tags):\n",
    "#     print tags\n",
    "#     letters_only = re.sub(\"[^a-zA-Z]\", \" \", tags) \n",
    "#     return map( lambda x: [x], letters_only.lower().split() )\n",
    "    return tags.split(\" \")\n",
    "\n",
    "# print separate_tags(\"hello googbye13 42 HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_html(raw_html):\n",
    "    if raw_html:\n",
    "        # remove html tags\n",
    "        soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "\n",
    "        [s.extract() for s in soup(['pre', 'code'])]\n",
    "            \n",
    "        question_text = soup.get_text()\n",
    "        \n",
    "        # remove everything but letters\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", question_text) \n",
    "        \n",
    "            \n",
    "        # normalize case\n",
    "        words = letters_only.lower().split()   \n",
    "\n",
    "        # remove stopwords         \n",
    "        meaningful_words = [w for w in words if not w in stops] \n",
    "        \n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        meaningful_word_stems = map(lambda x: wordnet_lemmatizer.lemmatize(x) , meaningful_words)\n",
    "        return( \" \".join( meaningful_word_stems )) \n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "# strip_html(df_hash['robotics'].content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set of tags for each topic...\n",
      "\n",
      "biology\n",
      "'s size is \n",
      "0        [ribosome, binding-sites, translation, synthet...\n",
      "1                                      [rna, biochemistry]\n",
      "2                   [immunology, cell-biology, hematology]\n",
      "3                                           [cell-culture]\n",
      "4            [splicing, mrna, spliceosome, introns, exons]\n",
      "5                   [dna, biochemistry, molecular-biology]\n",
      "6                                 [neuroscience, synapses]\n",
      "7                                               [plasmids]\n",
      "8        [molecular-genetics, gene-expression, experime...\n",
      "9                  [evolution, mitochondria, chloroplasts]\n",
      "10                           [high-throughput, cell-based]\n",
      "11                  [molecular-biology, synthetic-biology]\n",
      "12                              [bioinformatics, homework]\n",
      "13                              [neuroscience, immunology]\n",
      "14                                     [splicing, histone]\n",
      "15                      [genomics, gene-annotation, exons]\n",
      "16                     [microbiology, virology, influenza]\n",
      "17                                           [epigenetics]\n",
      "18                      [molecular-biology, dna-isolation]\n",
      "19               [cell-membrane, adaptation, cell-biology]\n",
      "20                              [transcription, chromatin]\n",
      "21                            [biochemistry, neuroscience]\n",
      "22       [molecular-biology, transcription, rna-interfe...\n",
      "23            [neuroscience, endocrinology, human-biology]\n",
      "24                         [bioinformatics, phylogenetics]\n",
      "25                           [splicing, introns, genetics]\n",
      "26                                     [biochemistry, rna]\n",
      "27                            [microbiology, astrobiology]\n",
      "28                                 [dna, primer, genetics]\n",
      "29                   [microbiology, history, bacteriology]\n",
      "                               ...                        \n",
      "13166            [microbiology, health, trees, dendrology]\n",
      "13167                 [species-identification, entomology]\n",
      "13168    [human-biology, neuroscience, brain, vision, h...\n",
      "13169              [neuroscience, neuroanatomy, neurology]\n",
      "13170                                    [botany, mitosis]\n",
      "13171                                           [genetics]\n",
      "13172    [microbiology, hematology, blood-circulation, ...\n",
      "13173                                             [botany]\n",
      "13174                                    [enzyme-kinetics]\n",
      "13175                                [cell-biology, virus]\n",
      "13176                          [neuroscience, development]\n",
      "13177                    [molecular-biology, cell-biology]\n",
      "13178                                       [safety, heat]\n",
      "13179    [biochemistry, proteins, protein-folding, prot...\n",
      "13180                                           [genetics]\n",
      "13181    [human-biology, pathology, terminology, medici...\n",
      "13182    [human-biology, neuroscience, central-nervous-...\n",
      "13183                        [human-biology, biodiversity]\n",
      "13184                    [neuroscience, electrophysiology]\n",
      "13185                                   [zoology, anatomy]\n",
      "13186    [microbiology, pathology, medicine, pathogenes...\n",
      "13187           [zoology, toxicology, herpetology, poison]\n",
      "13188    [digestive-system, toxicology, digestion, gast...\n",
      "13189                 [species-identification, entomology]\n",
      "13190                                   [human-physiology]\n",
      "13191                                      [human-biology]\n",
      "13192                                    [evolution, food]\n",
      "13193                                         [cardiology]\n",
      "13194                                               [data]\n",
      "13195                                         [dendrology]\n",
      "Name: tags, dtype: object\n",
      "0    prokaryotic translation critical efficient tra...\n",
      "1    anyone suggestion prevent rnase contamination ...\n",
      "2    tortora writes principle anatomy physiology ly...\n",
      "3    various people lab prepare liter lb add kanamy...\n",
      "Name: content, dtype: object\n",
      "cooking\n",
      "'s size is \n",
      "0                               [baking, cookies, texture]\n",
      "1                              [oven, cooking-time, bacon]\n",
      "2                                                   [eggs]\n",
      "3        [substitutions, please-remove-this-tag, baking...\n",
      "4                [sauce, pasta, tomatoes, italian-cuisine]\n",
      "5                          [substitutions, herbs, parsley]\n",
      "6                        [food-safety, beef, cooking-time]\n",
      "7                                 [eggs, basics, poaching]\n",
      "8                                              [ice-cream]\n",
      "9                          [baking, chicken, cooking-time]\n",
      "10                         [grilling, salmon, cedar-plank]\n",
      "11                  [baking, flour, measurements, sifting]\n",
      "12                [storage-method, storage-lifetime, fats]\n",
      "13           [canning, pressure-canner, food-preservation]\n",
      "14                   [spices, resources, basics, learning]\n",
      "15       [food-safety, storage-method, storage-lifetime...\n",
      "16                                  [baking, bread, dough]\n",
      "17                        [rice, italian-cuisine, risotto]\n",
      "18                 [eggs, food-science, vinegar, poaching]\n",
      "19                                 [storage-method, bread]\n",
      "20            [knife-skills, resources, learning, cutting]\n",
      "21                        [nutrient-composition, calories]\n",
      "22          [storage-method, spices, organization, pantry]\n",
      "23              [storage-method, storage-lifetime, spices]\n",
      "24                              [conversion, measurements]\n",
      "25            [chicken, meat, chicken-breast, tenderizing]\n",
      "26                  [baking, pancakes, conversion, waffle]\n",
      "27                        [equipment, wok, seasoning-pans]\n",
      "28                                              [grilling]\n",
      "29                        [storage-method, ripe, avocados]\n",
      "                               ...                        \n",
      "15374    [sugar, food-identification, dairy, beverages,...\n",
      "15375                                            [thawing]\n",
      "15376                                   [baking, brownies]\n",
      "15377                                         [hamburgers]\n",
      "15378                                      [substitutions]\n",
      "15379                   [chili-peppers, hot-sauce, pepper]\n",
      "15380                                    [sauce, tomatoes]\n",
      "15381                                        [pasta, soup]\n",
      "15382                                                [jam]\n",
      "15383                                              [pasta]\n",
      "15384                                           [crockpot]\n",
      "15385                          [spicy-hot, soy, hot-sauce]\n",
      "15386                                               [salt]\n",
      "15387                              [chocolate, sugar, raw]\n",
      "15388                                   [eggs, fried-eggs]\n",
      "15389                               [barbecue, hamburgers]\n",
      "15390        [substitutions, flavor, seasoning, spicy-hot]\n",
      "15391                           [oven, microwave, ceramic]\n",
      "15392                                               [fish]\n",
      "15393                                          [equipment]\n",
      "15394                                       [oil, coconut]\n",
      "15395                                        [carbonation]\n",
      "15396                             [chicken, chicken-stock]\n",
      "15397                              [food-safety, freezing]\n",
      "15398        [dough, japanese-cuisine, noodles, buckwheat]\n",
      "15399                      [eggs, poaching, high-altitude]\n",
      "15400                                           [frosting]\n",
      "15401                                             [baking]\n",
      "15402                                          [ice-cream]\n",
      "15403                    [fats, food-identification, mold]\n",
      "Name: tags, dtype: object\n",
      "0    chocolate chip cooky always crisp get chewy co...\n",
      "1    heard people cooking bacon oven laying strip c...\n",
      "2    always use brown extra large egg honestly say ...\n",
      "3                         use one place certain recipe\n",
      "Name: content, dtype: object\n",
      "travel\n",
      "'s size is \n",
      "0                         [caribbean, cruising, vacations]\n",
      "1        [guides, extreme-tourism, amazon-river, amazon...\n",
      "2        [loyalty-programs, routes, ewr, singapore-airl...\n",
      "3                                [romania, transportation]\n",
      "4                            [extreme-tourism, antarctica]\n",
      "5                  [usa, airport-transfer, taxis, seattle]\n",
      "6        [sightseeing, public-transport, transportation...\n",
      "7          [safety, international-travel, money, exchange]\n",
      "8         [russia, visas, china, mongolia, trans-siberian]\n",
      "9        [online-resources, transportation, peru, south...\n",
      "10                      [us-citizens, travel-agents, cuba]\n",
      "11                        [sightseeing, hungary, budapest]\n",
      "12       [europe, online-resources, planning, guides, t...\n",
      "13       [budget, cellphones, data-plans, communication...\n",
      "14                          [air-travel, around-the-world]\n",
      "15                  [sightseeing, planning, tourist-traps]\n",
      "16          [budget, europe, cellphones, mobile-operators]\n",
      "17                   [air-travel, usa, sightseeing, tours]\n",
      "18       [online-resources, international-travel, adven...\n",
      "19                       [planning, tropical-destinations]\n",
      "20       [destinations, adventure, activities, swimming...\n",
      "21       [transportation, taxis, automobiles, airport-t...\n",
      "22                  [sightseeing, estonia, tallinn, caves]\n",
      "23                         [china, trains, permits, tibet]\n",
      "24                                 [usa, florida, orlando]\n",
      "25        [luggage, airports, security, south-africa, jnb]\n",
      "26                      [health, japan, safety, radiation]\n",
      "27       [air-travel, budget, online-resources, uk, air...\n",
      "28            [israel, accommodation, palestine, tel-aviv]\n",
      "29                                      [france, children]\n",
      "                               ...                        \n",
      "19249                       [canada, cellphones, software]\n",
      "19250                                   [driving-licenses]\n",
      "19251                                    [routes, romania]\n",
      "19252                                   [luggage, vueling]\n",
      "19253               [thailand, ferries, sumatra-indonesia]\n",
      "19254                                 [canada, cellphones]\n",
      "19255           [schengen, india, application-status, vfs]\n",
      "19256    [usa, customs-and-immigration, europe, local-c...\n",
      "19257             [visas, schengen, france-schengen-visas]\n",
      "19258    [usa, food-and-drink, california, recommendati...\n",
      "19259                   [air-travel, usa, airline-booking]\n",
      "19260       [visas, schengen, transit, ukrainian-citizens]\n",
      "19261                           [legal, safety, souvenirs]\n",
      "19262        [airports, cellphones, south-korea, internet]\n",
      "19263                                          [visas, uk]\n",
      "19264    [air-travel, electronic-items, hand-luggage, s...\n",
      "19265    [indian-citizens, germany, passport-stamps, cr...\n",
      "19266    [germany, payment-cards, austria, czech-republic]\n",
      "19267        [air-travel, usa, lhr, dublin, pre-clearance]\n",
      "19268    [air-travel, luggage, electronic-items, hand-l...\n",
      "19269                     [argentina, trekking, patagonia]\n",
      "19270    [india, airport-transfer, taxis, price, new-de...\n",
      "19271                       [india, transportation, nepal]\n",
      "19272        [usa, esta, us-visa-waiver-program, vwp, iad]\n",
      "19273    [air-travel, customs-and-immigration, jfk, ewr...\n",
      "19274    [usa, food-and-drink, california, tipping, san...\n",
      "19275                 [uk, canada, france, culture, gifts]\n",
      "19276    [customs-and-immigration, officials, registrat...\n",
      "19277                                     [visas, austria]\n",
      "19278                                           [untagged]\n",
      "Name: tags, dtype: object\n",
      "0    fianc e looking good caribbean cruise october ...\n",
      "1    one definition question also one interest pers...\n",
      "2    singapore airline business class flight ewr si...\n",
      "3    another definition question interested easiest...\n",
      "Name: content, dtype: object\n",
      "robotics\n",
      "'s size is \n",
      "0                                       [soccer, control]\n",
      "1                                      [control, rcservo]\n",
      "2                                            [gait, walk]\n",
      "3                [microcontroller, arduino, raspberry-pi]\n",
      "4                                  [motion-planning, rrt]\n",
      "5                                    [software, platform]\n",
      "6                                     [software, circuit]\n",
      "7                 [odometry, localization, kalman-filter]\n",
      "8                                              [untagged]\n",
      "9                                     [soccer, mechanism]\n",
      "10                       [computer-vision, wheeled-robot]\n",
      "11                                           [quadcopter]\n",
      "12                                               [servos]\n",
      "13                           [localization, mobile-robot]\n",
      "14                                        [kinect, input]\n",
      "15                                                [wheel]\n",
      "16             [control, gyroscope, balance, two-wheeled]\n",
      "17                              [design, underwater, auv]\n",
      "18                             [underwater, battery, auv]\n",
      "19                              [electronics, protection]\n",
      "20                                    [localization, gps]\n",
      "21      [slam, localization, gps, mapping, acoustic-ra...\n",
      "22                     [servos, heat-management, cooling]\n",
      "23                              [sensors, failure, motor]\n",
      "24                               [two-wheeled, stability]\n",
      "25      [mobile-robot, design, movement, wheel, first-...\n",
      "26      [arduino, logic-control, stepper-motor, steppe...\n",
      "27                                         [mobile-robot]\n",
      "28                  [servos, mobile-robot, stepper-motor]\n",
      "29                               [motor, actuator, noise]\n",
      "                              ...                        \n",
      "2741                                             [servos]\n",
      "2742    [control, kalman-filter, imu, calibration, pre...\n",
      "2743                                           [3d-model]\n",
      "2744                                       [localization]\n",
      "2745                                                [ros]\n",
      "2746    [motor, robotic-arm, stepper-motor, servos, to...\n",
      "2747                                      [walking-robot]\n",
      "2748               [slam, computer-vision, stereo-vision]\n",
      "2749                               [mobile-robot, tracks]\n",
      "2750           [localization, lidar, precise-positioning]\n",
      "2751                             [sensors, imu, rotation]\n",
      "2752                        [computer-vision, automation]\n",
      "2753                                            [arduino]\n",
      "2754                        [quadcopter, microcontroller]\n",
      "2755                          [localization, slam, lidar]\n",
      "2756                                       [mobile-robot]\n",
      "2757                                      [wheeled-robot]\n",
      "2758                           [real-time, digital-audio]\n",
      "2759                         [motor, raspberry-pi, power]\n",
      "2760                                              [motor]\n",
      "2761                 [quadcopter, sensors, accelerometer]\n",
      "2762                          [motor, quadrature-encoder]\n",
      "2763               [quadcopter, accelerometer, gyroscope]\n",
      "2764                      [mobile-robot, torque, gearing]\n",
      "2765        [inverse-kinematics, c++, forward-kinematics]\n",
      "2766               [motor, robotic-arm, actuator, torque]\n",
      "2767                       [microcontroller, electronics]\n",
      "2768    [arduino, raspberry-pi, embedded-systems, firs...\n",
      "2769                          [slam, ekf, first-robotics]\n",
      "2770                                           [wireless]\n",
      "Name: tags, dtype: object\n",
      "0    imagine programming wheel soccer robot type co...\n",
      "1    got hobby servo power hd mg like able control ...\n",
      "2    http www oricomtech com project leg time htm l...\n",
      "3    looking starting point project preferably usin...\n",
      "Name: content, dtype: object\n",
      "crypto\n",
      "'s size is \n",
      "0                         [block-cipher, des, permutation]\n",
      "1        [oblivious-transfer, multiparty-computation, f...\n",
      "2                                            [sha-1, hash]\n",
      "3               [hash, cryptanalysis, preimage-resistance]\n",
      "4                            [encryption, rsa, public-key]\n",
      "5                               [des, encryption, s-boxes]\n",
      "6                     [dsa, bitcoin, digital-cash, ripemd]\n",
      "7                             [hash, implementation, salt]\n",
      "8                [encryption, aes, block-cipher, key-size]\n",
      "9                                        [hash, passwords]\n",
      "10       [cryptanalysis, block-cipher, differential-ana...\n",
      "11       [coding-theory, elliptic-curves, hermitian-cur...\n",
      "12                     [encryption, tls, public-key, keys]\n",
      "13                                [hash, salt, randomness]\n",
      "14       [cryptanalysis, classical-cipher, substitution...\n",
      "15                            [encryption, salt, database]\n",
      "16                                    [xor, stream-cipher]\n",
      "17         [encryption, hash, block-cipher, stream-cipher]\n",
      "18       [implementation, aes, side-channel-attack, tim...\n",
      "19                [cryptanalysis, one-time-pad, key-reuse]\n",
      "20              [encryption, des, modes-of-operation, cbc]\n",
      "21                      [public-key, protocol-design, tls]\n",
      "22                     [rsa, number-theory, prime-numbers]\n",
      "23                                                   [des]\n",
      "24                                        [authentication]\n",
      "25       [encryption, aes, s-boxes, permutation, block-...\n",
      "26                        [cryptanalysis, public-key, rsa]\n",
      "27                      [hash, passwords, protocol-design]\n",
      "28                       [cryptanalysis, algebraic-attack]\n",
      "29                   [encryption, resources, test-vectors]\n",
      "                               ...                        \n",
      "10402                           [aes, cryptanalysis, cmac]\n",
      "10403    [public-key, cryptanalysis, elliptic-curves, a...\n",
      "10404                          [password-hashing, augpake]\n",
      "10405                   [encryption, rsa, public-key, pgp]\n",
      "10406                          [rsa, public-key, tls, ssh]\n",
      "10407                                         [randomness]\n",
      "10408                                     [implementation]\n",
      "10409                     [symmetric, substitution-cipher]\n",
      "10410                              [encryption, symmetric]\n",
      "10411                               [signature, hmac, mac]\n",
      "10412    [hash, hmac, pseudo-random-function, terminology]\n",
      "10413                          [key-size, disk-encryption]\n",
      "10414                      [algorithm-design, terminology]\n",
      "10415                              [public-key, signature]\n",
      "10416                                       [block-cipher]\n",
      "10417                                     [aes, keys, mac]\n",
      "10418                                         [encryption]\n",
      "10419    [encryption, symmetric, modes-of-operation, se...\n",
      "10420                                               [java]\n",
      "10421    [signature, post-quantum-cryptography, lattice...\n",
      "10422                                               [hash]\n",
      "10423                            [rsa, modes-of-operation]\n",
      "10424                                               [hash]\n",
      "10425                                      [cryptanalysis]\n",
      "10426                  [rsa, cryptanalysis, prime-numbers]\n",
      "10427                   [hash, hmac, collision-resistance]\n",
      "10428                                      [hash, padding]\n",
      "10429                   [perfect-secrecy, forward-secrecy]\n",
      "10430                               [hash, diffie-hellman]\n",
      "10431               [encryption, aes, symmetric, key-wrap]\n",
      "Name: tags, dtype: object\n",
      "0    use permutation table first step de algorithm ...\n",
      "1    initiating oblivious transfer would someone us...\n",
      "2    know sha irreversible append length message pr...\n",
      "3    since cryptographic hash function simple compa...\n",
      "Name: content, dtype: object\n",
      "diy\n",
      "'s size is \n",
      "0                        [remodeling, basement, carpentry]\n",
      "1                                     [caulking, bathroom]\n",
      "2                                                [drywall]\n",
      "3                        [walls, load-bearing, structural]\n",
      "4                                     [repair, electrical]\n",
      "5                                          [crack, stucco]\n",
      "6                                                    [fan]\n",
      "7                                               [radiator]\n",
      "8                                     [drywall, wallpaper]\n",
      "9                                                [windows]\n",
      "10                                          [vinyl-siding]\n",
      "11                                              [concrete]\n",
      "12                                [repair, radiator, pipe]\n",
      "13                [electrical, fire-hazard, knob-and-tube]\n",
      "14                        [drywall, walls, framing, studs]\n",
      "15                                  [paint, floor, garage]\n",
      "16                                                 [tools]\n",
      "17                                       [paint, bathroom]\n",
      "18                                           [tile, grout]\n",
      "19                             [plumbing, sealing, toilet]\n",
      "20                                     [asphalt, driveway]\n",
      "21                                   [caulking, technique]\n",
      "22                                  [paint, ceiling, leak]\n",
      "23                                        [lighting, pole]\n",
      "24                             [draft, baseboard, sealing]\n",
      "25                          [repair, roof, pvc, treehouse]\n",
      "26                                                 [tools]\n",
      "27                                                  [lawn]\n",
      "28                       [water-heater, energy-efficiency]\n",
      "29                                   [concrete, technique]\n",
      "                               ...                        \n",
      "25888    [circuit-breaker, dryer, washing-machine, trou...\n",
      "25889                             [alarm, carbon-monoxide]\n",
      "25890                                  [recessed-lighting]\n",
      "25891                         [electrical, wiring, switch]\n",
      "25892                    [concrete, damage, cement, porch]\n",
      "25893                                          [generator]\n",
      "25894                                           [plumbing]\n",
      "25895                                 [garage-door-opener]\n",
      "25896                                    [washing-machine]\n",
      "25897                                    [electrical, led]\n",
      "25898                                    [washing-machine]\n",
      "25899                   [exterior, vapor-barrier, plastic]\n",
      "25900                             [noise, noise-reduction]\n",
      "25901                          [plastic, storage, drawers]\n",
      "25902                        [water, water-pressure, well]\n",
      "25903                       [kitchens, sealing, carpentry]\n",
      "25904                                       [pest-control]\n",
      "25905                            [electrical-distribution]\n",
      "25906                                               [sink]\n",
      "25907                                       [doors, knobs]\n",
      "25908                       [concrete, subfloor, hardwood]\n",
      "25909                                 [electrical, wiring]\n",
      "25910                                         [electrical]\n",
      "25911                         [electrical, wiring, socket]\n",
      "25912    [electrical, wiring, lighting, light-fixture, ...\n",
      "25913                         [water, foundation, grading]\n",
      "25914                                         [thermostat]\n",
      "25915                                         [electrical]\n",
      "25916                                  [thermostat-c-wire]\n",
      "25917                               [electrical, lighting]\n",
      "Name: tags, dtype: object\n",
      "0    looking finish basement simply want wall concr...\n",
      "1    would like recaulk bathtub ceramic tile wall m...\n",
      "2    going drywalling shortly wondering experience ...\n",
      "3    looking blue print many homeowner may way dete...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print \"Cleaning and parsing the training set of tags for each topic...\\n\"\n",
    "\n",
    "for topic, df in df_hash.iteritems():\n",
    "    if topic == \"test\":\n",
    "        next\n",
    "    else:\n",
    "        print topic\n",
    "        print \"'s size is \"\n",
    "\n",
    "        df.content = df.content.apply(lambda x: strip_html(x) )\n",
    "        df.title = df.title.apply(lambda x: strip_html(x) )\n",
    "        df.tags = df.tags.apply(lambda y: separate_tags(y) )\n",
    "        df.tags.replace(['', ' ', 'untagged'], np.nan, inplace=True)\n",
    "        df.dropna(subset=['tags'], inplace=True)\n",
    "        print df.tags\n",
    "        print df.content.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology\n",
      "[u'j', u'z', u'q', u'x', u'k', u'w', u'v', u'f', u'b', u'y']\n",
      "j\n",
      "5.13588667654\n",
      "z\n",
      "3.81192158838\n",
      "q\n",
      "3.57400745936\n",
      "x\n",
      "3.00618910811\n",
      "k\n",
      "2.75581408807\n",
      "w\n",
      "2.58933371721\n",
      "v\n",
      "2.19444545131\n",
      "f\n",
      "1.94976907942\n",
      "b\n",
      "1.88713001046\n",
      "y\n",
      "1.8024980336\n",
      "h\n",
      "1.72588143674\n",
      "g\n",
      "1.5484260696\n",
      "p\n",
      "1.46409552735\n",
      "u\n",
      "1.45163878465\n",
      "m\n",
      "1.395737625\n",
      "cooking\n",
      "[u'j', u'q', u'x', u'z', u'v', u'w', u'y', u'f', u'b', u'h']\n",
      "j\n",
      "4.26572046313\n",
      "q\n",
      "4.02370842751\n",
      "x\n",
      "3.81157317638\n",
      "z\n",
      "3.5391253485\n",
      "v\n",
      "2.35693410195\n",
      "w\n",
      "2.23797508968\n",
      "y\n",
      "2.12705584156\n",
      "f\n",
      "1.83587359053\n",
      "b\n",
      "1.81424632186\n",
      "h\n",
      "1.67660191628\n",
      "k\n",
      "1.67074501133\n",
      "m\n",
      "1.61759359919\n",
      "p\n",
      "1.60455747605\n",
      "d\n",
      "1.4738669733\n",
      "g\n",
      "1.46970506947\n",
      "travel\n",
      "[u'q', u'j', u'z', u'x', u'w', u'f', u'k', u'b', u'y', u'm']\n",
      "q\n",
      "3.92370114535\n",
      "j\n",
      "3.80463193588\n",
      "z\n",
      "3.49344925825\n",
      "x\n",
      "3.35475232233\n",
      "w\n",
      "2.20397280433\n",
      "f\n",
      "2.03379826088\n",
      "k\n",
      "1.96777513428\n",
      "b\n",
      "1.88526762739\n",
      "y\n",
      "1.76040030961\n",
      "m\n",
      "1.70200371149\n",
      "v\n",
      "1.63433039155\n",
      "h\n",
      "1.60085929244\n",
      "p\n",
      "1.47041865312\n",
      "d\n",
      "1.39889957156\n",
      "g\n",
      "1.39612093439\n",
      "robotics\n",
      "[u'z', u'j', u'x', u'q', u'k', u'w', u'y', u'v', u'f', u'h']\n",
      "z\n",
      "3.80933054789\n",
      "j\n",
      "3.7798298835\n",
      "x\n",
      "3.25057055804\n",
      "q\n",
      "3.00039833434\n",
      "k\n",
      "2.41557903067\n",
      "w\n",
      "2.36065193051\n",
      "y\n",
      "2.18208801083\n",
      "v\n",
      "2.11607998171\n",
      "f\n",
      "2.06875932552\n",
      "h\n",
      "1.99390133458\n",
      "b\n",
      "1.66119558075\n",
      "g\n",
      "1.49424901141\n",
      "p\n",
      "1.45767018738\n",
      "u\n",
      "1.42624223605\n",
      "d\n",
      "1.3745622761\n",
      "crypto\n",
      "[u'j', u'z', u'q', u'x', u'w', u'v', u'k', u'f', u'b', u'h']\n",
      "j\n",
      "4.92485296968\n",
      "z\n",
      "3.85913838452\n",
      "q\n",
      "3.71603754088\n",
      "x\n",
      "2.73901989063\n",
      "w\n",
      "2.48419583754\n",
      "v\n",
      "2.16079568249\n",
      "k\n",
      "1.94947201762\n",
      "f\n",
      "1.94280614921\n",
      "b\n",
      "1.90584988472\n",
      "h\n",
      "1.58970549884\n",
      "y\n",
      "1.54905638011\n",
      "g\n",
      "1.50078008041\n",
      "m\n",
      "1.42247856827\n",
      "u\n",
      "1.39407616892\n",
      "d\n",
      "1.39208809669\n",
      "diy\n",
      "[u'z', u'q', u'j', u'x', u'v', u'y', u'k', u'f', u'b', u'm']\n",
      "z\n",
      "4.40347629881\n",
      "q\n",
      "4.39423835783\n",
      "j\n",
      "4.39079601364\n",
      "x\n",
      "2.9566938067\n",
      "v\n",
      "2.33321247469\n",
      "y\n",
      "2.23807526729\n",
      "k\n",
      "2.18180436183\n",
      "f\n",
      "1.86933764236\n",
      "b\n",
      "1.84974436054\n",
      "m\n",
      "1.65265704402\n",
      "w\n",
      "1.61256744064\n",
      "h\n",
      "1.57910498775\n",
      "p\n",
      "1.50061518653\n",
      "g\n",
      "1.44967839384\n",
      "u\n",
      "1.43866977062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "for topic, df in df_hash.iteritems():\n",
    "    if topic == \"test\":\n",
    "        next\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(analyzer='word', tokenizer=lambda doc: doc, lowercase=False , stop_words=\"english\" ,min_df=1 ) \n",
    "        print topic\n",
    "        X = vectorizer.fit_transform(df.title)\n",
    "        indices = np.argsort(vectorizer.idf_)[::-1]\n",
    "        features = np.array(vectorizer.get_feature_names())\n",
    "        top_n = 10\n",
    "        top_features = [features[i] for i in indices[:top_n]]\n",
    "        print top_features\n",
    "\n",
    "        for top_feat_index in indices[:15]:\n",
    "            print features[top_feat_index]\n",
    "            print vectorizer.idf_[top_feat_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 4)\n"
     ]
    }
   ],
   "source": [
    "print df_hash[\"robotics\"].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# class QuestionStripper(BaseEstimator, TransformerMixin):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self = self\n",
    "#         self.df = df  # e.g. pass in a column name to extract\n",
    "#         self.topic_size = df.size\n",
    "        \n",
    "#     def transform(self, X, y=None):\n",
    "#         return do_something_to(X, self.vars)  # where the actual feature extraction happens\n",
    "#         print \"'s size is \"\n",
    "#         print self.topic_size\n",
    "#         return X.apply(lambda x: strip_html(x) )\n",
    "        \n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self  # generally does nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                           [soccer, control]\n",
      "1                          [control, rcservo]\n",
      "2                                [gait, walk]\n",
      "3    [microcontroller, arduino, raspberry-pi]\n",
      "4                      [motion-planning, rrt]\n",
      "Name: tags, dtype: object\n",
      "(2771, 4)\n",
      "0    <p>I often hear about subatomic particles havi...\n",
      "1    <p>How would you explain string theory to non ...\n",
      "2    <p>This is a question that has been posted at ...\n",
      "3    <p>What are the main problems that we need to ...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df_hash[\"robotics\"].tags.head(5)\n",
    "print df_hash[\"robotics\"].shape\n",
    "print df.content.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named skmultilearn.ensemble",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4f5e83c03787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskmultilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRakelD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRakelO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskmultilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_transform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinaryRelevance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelPowerset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named skmultilearn.ensemble"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier, OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from math import sqrt\n",
    "from skmultilearn.ensemble import RakelD, RakelO\n",
    "from skmultilearn.problem_transform import BinaryRelevance, LabelPowerset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "from time import time\n",
    "from skmultilearn.problem_transform import BinaryRelevance  \n",
    "# from nltk.classify.scikitlearn import SklearnClassifier\n",
    "# from collections import defaultdict\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "# parameters = {\n",
    "#     'rakel__labelset_size': range(1, 3),\n",
    "#     'classifier': [LabelPowerset(), SVC()],\n",
    "#     'rakel__classifier': \"classifier\"\n",
    "#     }\n",
    "\n",
    "# parameters = {'tree__max_depth': range(7, 20),\n",
    "#               \"tree__n_estimators\": [10, 50, 100],\n",
    "#               \"tree__bootstrap\": [ False],\n",
    "#               \"tree__criterion\": [\"gini\", \"entropy\"]}\n",
    "# parameters = {\n",
    "#     'rakel__labelset_size': range(1, 3),\n",
    "#     'vectorizer__ngram_range': range(1,2),\n",
    "#     'rakel__classifier': [LabelPowerset(), BinaryRelevance()],\n",
    "#     'rakel__classifier__classifier': [MultinomialNB()],\n",
    "#     'rakel__classifier__classifier__alpha': [0.7, 1.0],\n",
    "# }\n",
    "\n",
    "# TfidfTransformer = TfidfVectorizer(analyzer = \"word\",   \\\n",
    "\n",
    "        \n",
    "\n",
    "# use a full grid over all parameters\n",
    "# param_grid = {\"max_depth\": [3, None],\n",
    "#               \"max_features\": [1, 3, 10],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "# parameters = {'svc__estimator__kernel': ['rbf', 'poly']}\n",
    "#               'svc__estimator__degree':[1, 2, 3] }\n",
    "\n",
    "# parameters = dict(svc__estimator__C=np.logspace(-5,0,5), svc__estimator__gamma=np.logspace(-2, 2, 10))\n",
    "\n",
    "#     print(\"Best parameters set found on development set:\")\n",
    "#     print()\n",
    "#     print(clf.best_params_)\n",
    "#     print()\n",
    "#     print(\"Grid scores on development set:\")\n",
    "\n",
    "        \n",
    "df = df_hash[\"robotics\"]\n",
    "# for topic, df in df_hash.iteritems():\n",
    "print \"splitting\"\n",
    "\n",
    "\n",
    "#     tf = TfidfVectorizer()\n",
    "#     X = tf.fit_transform(df.content.values)\n",
    "#     Y = df.tags.values\n",
    "print \"len df.tags\"\n",
    "print len(df.tags)\n",
    "print df.tags.shape\n",
    "print df.tags.head(5)\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = pd.DataFrame( mlb.fit_transform(df.tags) )\n",
    "\n",
    "print \"y shape\"\n",
    "print Y.shape\n",
    "print \"y\"\n",
    "print Y.head(5)\n",
    "print type(Y)\n",
    "true_k = len(Y)\n",
    "print \"true K: \\n\"\n",
    "print int(sqrt(true_k))\n",
    "print int(true_k/100)\n",
    "# parameters = {\n",
    "#         \"rf_classifier__n_estimators\" : [ 5 , 10],\n",
    "#     \"dt_class__max_depth\" : [20,50, 100, 500 ],\n",
    "#     \"dt_class__criterion\" : [\"gini\", \"entropy\"]\n",
    "# } \n",
    "\n",
    "#     steps = [   ('vectorizer', CountVectorizer(stop_words=\"english\", strip_accents='unicode')),\n",
    "steps = [('tfidf', TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False , analyzer = \"word\",\n",
    "                                   stop_words=\"english\",max_features = 5000 ) ),\n",
    "#         ('rakel', RakelD(MultinomialNB(alpha=0.7), labelset_size=true_k))]\n",
    "#             ('rf_classifier', RandomForestClassifier(n_estimators= 7, max_depth=20, random_state=42 ))]\n",
    "            (\"dt_class\", OneVsRestClassifier(DecisionTreeClassifier( random_state = 42)))]\n",
    "#             ( 'kmeans_cluster', MiniBatchKMeans(n_clusters=int(sqrt(true_k)), init='k-means++', n_init=1,\n",
    "#                              init_size=1000, batch_size=1000) ) ]\n",
    "#             ('svc', OneVsRestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "#     Y = mlb.fit_transform(df.tags)z\n",
    "#     print Y.shape\n",
    "#     print Y\n",
    "#     print df.tags.head(5)\n",
    "#     X_train, X_test, y_train, y_test_vect = train_test_split(df.content,\\\n",
    "#                                                         Y, \\\n",
    "#                                                         test_size=0.33,\\\n",
    "#                                                         random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "#     scorer = make_scorer(f1_score, average=\"weighted\")\n",
    "#     Y_test = mlb.fit_transform(y_test)\n",
    "#     scores = ['precision', 'recall']\n",
    "\n",
    "#     for score in scores:\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "#     cv = GridSearchCV( pipeline, scoring='f1')\n",
    "#     cv = GridSearchCV( pipeline, param_grid = parameters, scoring='f1')\n",
    "#                            scoring='%s_macro' % score)\n",
    "\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "# clf = GridSearchCV(pipeline, parameters, cv=10)\n",
    "# clf.fit( df.content, Y )\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     y_predicted_vect = pipeline.predict(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# print clf.best_estimator_\n",
    "# print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = clf.best_estimator_.get_params()\n",
    "# print best_parameters\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# print clf.cv_results_.keys()\n",
    "# print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "#     results = cross_val_score(clf, X, Y)\n",
    "#     print results\n",
    "#     y_prediction = clf.predict( X_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for topic, df in df_hash.iteritems():\n",
    "print \"evaluating\"\n",
    "t0 = time()\n",
    "y_prediction =  cross_val_predict(pipeline, df.content, Y, cv=10 )\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print \"y_prediction: \\n\"\n",
    "print y_prediction.shape\n",
    "print y_prediction\n",
    "print type(y_prediction)\n",
    "print type(y_prediction[0])\n",
    "print y_prediction.astype(int)\n",
    "#     print y_predicted_vect.to_dense\n",
    "\n",
    "Y_inv = mlb.inverse_transform(y_prediction)\n",
    "#     y_test_inv = mlb.inverse_transform(y_test_vect.values)\n",
    "#     y_pred_inv = mlb.inverse_transform(y_predicted_vect)\n",
    "#     y_pred_inv = y_predicted_vect.apply(lambda x: d[x].inverse_transform(x))\n",
    "#     y_test_inv = y_test_vect.apply(lambda x: d[x].inverse_transform(x))\n",
    "\n",
    "#     print clf.best_estimator_\n",
    "print \"baallss\"\n",
    "#     print Y_inv\n",
    "print accuracy_score(Y, y_prediction) \n",
    "report = classification_report(Y, y_prediction) \n",
    "print(report)\n",
    "\n",
    "#     print cv.best_score_\n",
    "#     print cv.best_params_\n",
    "#     print clf.feature_importances_  \n",
    "#     model = SelectFromModel(clf, prefit=True)\n",
    "#     print model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y = mlb.inverse_transform(Y)\n",
    "index = 0\n",
    "for actual, pred in zip(df.tags, Y_inv):\n",
    "        print('index: {0} :: {1} => {2}'.format(index, actual, ', '.join(pred)))\n",
    "        index = index +1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_prediction.shape\n",
    "# print y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print confusion_matrix(Y, y_prediction) \n",
    "# print y_pred_inv\n",
    "# print mlb.inverse_transform(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.civisanalytics.com/blog/workflows-in-python-using-pipeline-and-gridsearchcv-for-more-compact-and-comprehensive-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "# train_data_features = train_data_features.toarray()\n",
    "# report = classification_report(Y, y_prediction) \n",
    "# print report\n",
    "f1_score(Y, y_prediction, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print train_data_features.shape\n",
    "# print \"4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
